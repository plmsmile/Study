{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import data_helper as dh\n",
    "from data_helper import get_variable\n",
    "from model import *\n",
    "from masked_cross_entropy import *\n",
    "import show as sh\n",
    "\n",
    "#reload(sh)\n",
    "\n",
    "import train_helper as th\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "en_file = \"{}/{}\".format(data_dir, \"seg_en\")\n",
    "zh_file = \"{}/{}\".format(data_dir, \"seg_zh\")\n",
    "TARGET_MAX_LEN = 25\n",
    "USE_CUDA = False\n",
    "print(en_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs, input_lang, target_lang = dh.read_data(en_file, zh_file, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 模型配置\n",
    "encoder_bidir = False\n",
    "score_method = 'general'\n",
    "hidden_size = 50\n",
    "n_layers = 2\n",
    "dropout_p = 0.1\n",
    "batch_size = 5\n",
    "\n",
    "# 训练和优化配置\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "# n_epochs = 50000\n",
    "# epoch = 0\n",
    "# plot_every = 20\n",
    "# print_every = 100\n",
    "# evaluate_every = 1000\n",
    "n_epochs = 10\n",
    "epoch = 0\n",
    "plot_every = 2\n",
    "print_every = 1\n",
    "evaluate_every = 5\n",
    "\n",
    "train_conf = {'clip': clip, 'teacher_forcing_ratio': teacher_forcing_ratio}\n",
    "\n",
    "# 初始化模型\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers=n_layers, \n",
    "                     dropout_p=dropout_p, bidir=encoder_bidir)\n",
    "decoder = AttnDecoderRNN(hidden_size, target_lang.n_words, score_method=score_method, \n",
    "                         n_layers=n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# 优化器和loss\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "print (encoder)\n",
    "print (decoder)\n",
    "\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0\n",
    "plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# job = sconce.Job('seq2seq-translate', {\n",
    "#     'encoder_bidir': encoder_bidir,\n",
    "#     'score_method': score_method,\n",
    "#     'n_layers': n_layers,\n",
    "#     'hidden_size': hidden_size,\n",
    "#     'learning_rate': learning_rate,\n",
    "#     'teacher_forcing_ratio': teacher_forcing_ratio,\n",
    "#     #'decoder_learning_ratio': decoder_learning_ratio,\n",
    "# })\n",
    "# job.plot_every = plot_every\n",
    "# job.log_every = print_every\n",
    "import sys\n",
    "print ('aa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "\n",
    "# vis = sh.vis\n",
    "# hostname = sh.HOSTIP\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "    input_batches, input_lengths, target_batches, target_lengths = dh.random_batch(\n",
    "        batch_size, pairs, input_lang, target_lang)\n",
    "    loss, ec, dc = th.train(input_batches, input_lengths,\n",
    "                         target_batches, target_lengths, encoder, decoder,\n",
    "                         encoder_optimizer, decoder_optimizer, train_conf)\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    eca += ec\n",
    "    dca += dc\n",
    "    #job.record(epoch, loss)\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (sh.time_since(start, float(epoch) / n_epochs),\n",
    "                                               epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print (print_summary)\n",
    "    \n",
    "    if epoch % evaluate_every == 0:\n",
    "        th.evaluate_randomly(pairs, input_lang, target_lang, encoder, decoder, False, True, False)\n",
    "    \n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "        \n",
    "        # TODO: Running average helper\n",
    "#         ecs.append(eca / plot_every)\n",
    "#         dcs.append(dca / plot_every)\n",
    "#         ecs_win = 'encoder grad (%s)' % hostname\n",
    "#         dcs_win = 'decoder grad (%s)' % hostname\n",
    "#         vis.line(np.array(ecs), win=ecs_win, opts={'title': ecs_win})\n",
    "#         vis.line(np.array(dcs), win=dcs_win, opts={'title': dcs_win})\n",
    "#         eca = 0\n",
    "#         dca = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = 1\n",
    "def func():\n",
    "    print ('aaaa:', aa)\n",
    "func()\n",
    "a = torch.randn(1, 2, 3)\n",
    "print (a.size(2), a.size()[2])\n",
    "a = [[1]]\n",
    "b = [2]\n",
    "print (torch.LongTensor(a))\n",
    "print (torch.LongTensor(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# job = sconce.Job('my-neural-network', {\n",
    "#     'n_layers': 6,\n",
    "#     'hidden_size': 250,\n",
    "#     'learning_rate': 0.001\n",
    "# })\n",
    "# # Record x, y values\n",
    "# for x in range(1000):\n",
    "#     y = x+2\n",
    "#     job.record(x, y)\n",
    "\n",
    "words = [dh.SOS_token] * 2\n",
    "decoder_input = dh.get_variable(torch.LongTensor(words))\n",
    "print (words)\n",
    "print (decoder_input.size())\n",
    "import torch.nn as nn\n",
    "embedding = nn.Embedding(10, 5)\n",
    "res = embedding(decoder_input)\n",
    "print (res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "\n",
    "reload(sys)  \n",
    "stdi, stdo, stde = sys.stdin, sys.stdout, sys.stderr\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdin, sys.stdout, sys.stderr = stdi, stdo, stde\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.matplotlib_fname()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['simhei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False   #-号为方块问题\n",
    "plt.plot((1,2,3),(4,3,-1))\n",
    "\n",
    "s = \"横坐标\"\n",
    "\n",
    "plt.xlabel(unicode(s))\n",
    "plt.ylabel(u'纵坐标')\n",
    "plt.show()\n",
    "print (s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
