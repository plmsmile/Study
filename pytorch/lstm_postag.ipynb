{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Everybody': 5, 'ate': 2, 'apple': 4, 'that': 7, 'read': 6, 'dog': 1, 'book': 8, 'the': 3, 'The': 0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "'''准备数据'''\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", 'V', \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "# 给单词编码\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print word_to_ix\n",
    "tag_to_ix = {\"DET\":0, \"NN\":1, \"V\":2}\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    '''把seq转换成ix列表，Variable格式。\n",
    "    Args:\n",
    "        seq: 句子，单词序列或者词性序列\n",
    "        to_ix: 是word_to_ix, 或者tag_to_ix\n",
    "    Returns:\n",
    "        res: Variable, size = len(seq)\n",
    "    '''\n",
    "    idxs = [to_ix[word] for word in seq]\n",
    "    res = Variable(torch.LongTensor(idxs))\n",
    "    return res\n",
    "    \n",
    "'''超参设置'''\n",
    "# 一般32,64\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'ate', 'the', 'apple']\n",
      "Variable containing:\n",
      "-0.9724 -1.1028 -1.2382\n",
      "-0.9942 -1.1470 -1.1636\n",
      "-0.9147 -1.1315 -1.2844\n",
      "-0.9943 -1.1123 -1.1999\n",
      "-0.9829 -1.0992 -1.2289\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "Variable containing:\n",
      "-0.3184 -1.7903 -2.2464\n",
      "-1.7638 -0.5437 -1.3943\n",
      "-1.3609 -0.7046 -1.3892\n",
      "-0.4327 -1.4474 -2.1536\n",
      "-1.8662 -0.3600 -1.9133\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''网络模型'''\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # (词汇总数量, embedding维度)\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # embedding as input, output hidden_dim \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # linear hidden state to tag  space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        '''init hidden, h0 and c0'''\n",
    "        # (num_layers*num_directions, minibatch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(1, 1, self.hidden_dim))\n",
    "        c0 = Variable(torch.zeros(1, 1, self.hidden_dim))\n",
    "        return (h0, c0)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        ''' 前向计算\n",
    "        Args:\n",
    "            sentence: 单词列表，用id表示。Variable格式\n",
    "        Returns:\n",
    "            标签得分\n",
    "        '''\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden =  self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        return tag_scores\n",
    " \n",
    "'''定义loss和优化器'''\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "\n",
    "loss_func = nn.NLLLoss()    # it is useful when you have an unbalanced training set\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "print training_data[0][0]\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "#print inputs.data\n",
    "tag_scores = model(inputs)\n",
    "print tag_scores\n",
    "\n",
    "'''训练网络'''\n",
    "for epoch in range(100):\n",
    "    for sentence, tags in training_data:\n",
    "        # 1. 清空梯度和初始化参数\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        # 2. 准备数据\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        tags_in = prepare_sequence(tags, tag_to_ix)\n",
    "        # 3. 前向计算\n",
    "        tag_scores = model(sentence_in)\n",
    "        # 4. 计算误差，梯度，更新参数\n",
    "        loss = loss_func(tag_scores, tags_in)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "#print inputs.data\n",
    "tag_scores = model(inputs)\n",
    "print tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API总结**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3])\n",
      "Variable containing:\n",
      " 0.5355 -1.1695  0.9449\n",
      "-2.2623  0.3127  0.1137\n",
      " 1.3729 -1.6990  0.0285\n",
      "-0.1547  0.2261 -0.6028\n",
      "-0.4340 -1.3596 -0.4329\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# num_embeddings: vocab_size, embedding_dim: single embedding vector dim\n",
    "embedding = nn.Embedding(num_embeddings = 10, embedding_dim = 3)\n",
    "inputs = Variable(torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])) \n",
    "print embedding(inputs).data.size()\n",
    "# 一共5个词，5个向量，每个向量3维\n",
    "print embedding(Variable(torch.LongTensor([1, 2, 3, 4, 5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
